{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "914677a2",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Cell 1 â€” Import & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a57f9781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (76529, 24)\n",
      "Target distribution:\n",
      " is_high_risk\n",
      "0    0.941787\n",
      "1    0.058213\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load processed data\n",
    "df = pd.read_parquet(\"../../data/processed/processed_data.parquet\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[\"is_high_risk\"])\n",
    "y = df[\"is_high_risk\"]\n",
    "\n",
    "print(\"Data shape:\", X.shape)\n",
    "print(\"Target distribution:\\n\", y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e0506",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Cell 2 â€” Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1f118b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = df.drop(columns=[\"is_high_risk\"])\n",
    "y = df[\"is_high_risk\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30653273",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Cell 3 â€” Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b42ae073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Simple baseline model\n",
    "lr = LogisticRegression(\n",
    "    random_state=42, \n",
    "    class_weight=\"balanced\", \n",
    "    max_iter=500\n",
    ")\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_prob_lr = lr.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828c14d1",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Cell 4 â€” Random Forest with Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6206f5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution BEFORE SMOTE:\n",
      "is_high_risk\n",
      "0    0.941787\n",
      "1    0.058213\n",
      "Name: proportion, dtype: float64\n",
      "Class distribution AFTER SMOTE:\n",
      "is_high_risk\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=  14.5s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=  14.8s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=  15.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=  15.3s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=  10.0s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=  10.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=  10.9s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=  29.8s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=300; total time=  29.7s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=  14.9s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=  30.3s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=300; total time=  30.7s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=300; total time=  31.3s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=  32.3s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=300; total time=  43.5s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=300; total time=  44.4s\n",
      "[CV] END max_depth=5, min_samples_split=10, n_estimators=500; total time=  30.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=300; total time=  46.9s\n",
      "[CV] END max_depth=5, min_samples_split=10, n_estimators=500; total time=  28.0s\n",
      "[CV] END max_depth=5, min_samples_split=10, n_estimators=500; total time=  28.5s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=500; total time= 1.0min\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=500; total time= 1.0min\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=500; total time= 1.0min\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=500; total time=  37.9s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=500; total time=  36.4s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=500; total time= 1.1min\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=500; total time=  40.8s\n",
      "Best RF params: {'n_estimators': 300, 'min_samples_split': 5, 'max_depth': None}\n",
      "\n",
      "Optimal Threshold found: 0.30\n",
      "Best F1 score at optimal threshold: 0.3678\n",
      "\n",
      "Random Forest Metrics after SMOTE + Threshold Tuning:\n",
      "accuracy: 0.8763\n",
      "precision: 0.2618\n",
      "recall: 0.6184\n",
      "f1: 0.3678\n",
      "roc_auc: 0.9050\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9742    0.8922    0.9314     14415\n",
      "           1     0.2618    0.6184    0.3678       891\n",
      "\n",
      "    accuracy                         0.8763     15306\n",
      "   macro avg     0.6180    0.7553    0.6496     15306\n",
      "weighted avg     0.9328    0.8763    0.8986     15306\n",
      "\n",
      "Logged Random Forest model to MLflow run a8772415391b444594bb56f22182a78e\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    ")\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Drop leakage columns if present\n",
    "# ---------------------------------------------------\n",
    "cols_to_drop = [\"FraudResult\"]\n",
    "\n",
    "for col in cols_to_drop:\n",
    "    if col in X_train.columns:\n",
    "        X_train = X_train.drop(columns=[col])\n",
    "    if col in X_val.columns:\n",
    "        X_val = X_val.drop(columns=[col])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# SMOTE\n",
    "# ---------------------------------------------------\n",
    "print(\"Class distribution BEFORE SMOTE:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution AFTER SMOTE:\")\n",
    "print(y_train_smote.value_counts(normalize=True))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Random Forest Hyperparameter Tuning\n",
    "# ---------------------------------------------------\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [5, 10, 20, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "search_rf = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "search_rf.fit(X_train_smote, y_train_smote)\n",
    "best_rf = search_rf.best_estimator_\n",
    "\n",
    "print(\"Best RF params:\", search_rf.best_params_)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Ensure columns match in validation set\n",
    "# ---------------------------------------------------\n",
    "missing_cols = set(X_train_smote.columns) - set(X_val.columns)\n",
    "for col in missing_cols:\n",
    "    X_val[col] = 0\n",
    "\n",
    "# Reorder columns to match\n",
    "X_val = X_val[X_train_smote.columns]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Predict probabilities on Validation Set\n",
    "# ---------------------------------------------------\n",
    "y_prob_rf = best_rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Threshold Tuning\n",
    "# ---------------------------------------------------\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "best_thresh = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (y_prob_rf >= t).astype(int)\n",
    "    f1 = f1_score(y_val, preds, zero_division=0)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"\\nOptimal Threshold found: {best_thresh:.2f}\")\n",
    "print(f\"Best F1 score at optimal threshold: {best_f1:.4f}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Final predictions and metrics\n",
    "# ---------------------------------------------------\n",
    "y_pred_rf = (y_prob_rf >= best_thresh).astype(int)\n",
    "\n",
    "metrics_rf = {\n",
    "    \"accuracy\": accuracy_score(y_val, y_pred_rf),\n",
    "    \"precision\": precision_score(y_val, y_pred_rf, zero_division=0),\n",
    "    \"recall\": recall_score(y_val, y_pred_rf, zero_division=0),\n",
    "    \"f1\": f1_score(y_val, y_pred_rf, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(y_val, y_prob_rf),\n",
    "}\n",
    "\n",
    "print(\"\\nRandom Forest Metrics after SMOTE + Threshold Tuning:\")\n",
    "for k, v in metrics_rf.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_rf, digits=4))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# MLflow Logging\n",
    "# ---------------------------------------------------\n",
    "mlflow.set_experiment(\"credit-risk-modeling\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"RandomForest_SMOTE_ThresholdTuned\") as run:\n",
    "    mlflow.log_params(search_rf.best_params_)\n",
    "    mlflow.log_metrics(metrics_rf)\n",
    "    mlflow.sklearn.log_model(best_rf, \"model\")\n",
    "    mlflow.log_param(\"optimal_threshold\", best_thresh)\n",
    "    print(\"Logged Random Forest model to MLflow run\", run.info.run_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd7f4b2",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Cell 5 â€” Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c04a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression metrics:\n",
      " {'accuracy': 0.5715405723245786, 'precision': 0.11776608660461352, 'recall': 0.9797979797979798, 'f1': 0.21026011560693642, 'roc_auc': 0.7787303800715756}\n",
      "Random Forest metrics:\n",
      " {'accuracy': 0.9315301189076179, 'precision': 0.3794162826420891, 'recall': 0.2772166105499439, 'f1': 0.3203631647211414, 'roc_auc': 0.9151988532957431}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_prob):\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_prob),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "lr_metrics = evaluate_model(y_test, y_pred_lr, y_prob_lr)\n",
    "rf_metrics = evaluate_model(y_test, y_pred_rf, y_prob_rf)\n",
    "\n",
    "print(\"Logistic Regression metrics:\\n\", lr_metrics)\n",
    "print(\"Random Forest metrics:\\n\", rf_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9375f0e9",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Cell 6 â€” Track in MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de4c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'CreditRiskModel' already exists. Creating a new version of this model...\n",
      "2025/06/29 13:05:36 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: CreditRiskModel, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered in MLflow Model Registry!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'CreditRiskModel'.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "mlflow.set_tracking_uri(\"../../mlruns\")\n",
    "mlflow.set_experiment(\"credit-risk-modeling\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"RandomForest\") as run:\n",
    "    mlflow.sklearn.log_model(best_rf, \"model\")\n",
    "    mlflow.log_params(search.best_params_)\n",
    "    mlflow.log_metrics(rf_metrics)\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "mlflow.register_model(model_uri, \"CreditRiskModel\")\n",
    "\n",
    "print(\"Model registered in MLflow Model Registry!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "398ad29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution BEFORE SMOTE:\n",
      "is_high_risk\n",
      "0    0.941787\n",
      "1    0.058213\n",
      "Name: proportion, dtype: float64\n",
      "Class distribution AFTER SMOTE:\n",
      "is_high_risk\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=  22.3s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=  22.6s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=  22.5s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=  22.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=  23.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=  22.8s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=  33.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=  34.6s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=  35.4s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=  36.5s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=  37.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  42.8s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  42.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  43.7s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  43.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  44.3s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  46.7s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=  30.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time= 1.0min\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time= 1.1min\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  52.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  53.6s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  53.7s\n",
      "Best parameters for GBM:\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Gradient Boosting Validation Metrics after SMOTE:\n",
      "accuracy: 0.9020\n",
      "precision: 0.2936\n",
      "recall: 0.4860\n",
      "f1: 0.3660\n",
      "roc_auc: 0.9061\n",
      "Logged GBM model to MLflow run 5eeb4412e25b496395ca9fcc4b1bbff9\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution BEFORE SMOTE:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Apply SMOTE\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Instantiate SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution AFTER SMOTE:\")\n",
    "print(pd.Series(y_train_resampled).value_counts(normalize=True))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Train GBM with hyperparameter tuning\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"subsample\": [0.8],\n",
    "}\n",
    "\n",
    "gbm = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "search_gbm = GridSearchCV(\n",
    "    gbm,\n",
    "    param_grid,\n",
    "    scoring=\"f1\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "search_gbm.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "best_gbm = search_gbm.best_estimator_\n",
    "\n",
    "print(\"Best parameters for GBM:\")\n",
    "print(search_gbm.best_params_)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Evaluate on validation set\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "y_pred = best_gbm.predict(X_val)\n",
    "y_proba = best_gbm.predict_proba(X_val)[:, 1]\n",
    "\n",
    "metrics_gbm = {\n",
    "    \"accuracy\": accuracy_score(y_val, y_pred),\n",
    "    \"precision\": precision_score(y_val, y_pred, zero_division=0),\n",
    "    \"recall\": recall_score(y_val, y_pred, zero_division=0),\n",
    "    \"f1\": f1_score(y_val, y_pred, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(y_val, y_proba),\n",
    "}\n",
    "\n",
    "print(\"\\nGradient Boosting Validation Metrics after SMOTE:\")\n",
    "for metric, value in metrics_gbm.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Log to MLflow\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Ensure MLflow tracking directory exists\n",
    "import os\n",
    "\n",
    "tracking_dir = \"../../mlruns\"\n",
    "if not os.path.exists(tracking_dir):\n",
    "    os.makedirs(tracking_dir)\n",
    "\n",
    "mlflow.set_tracking_uri(f\"file:{tracking_dir}\")\n",
    "mlflow.set_experiment(\"credit-risk-modeling\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"GBM_with_SMOTE\") as run:\n",
    "    mlflow.log_params(search_gbm.best_params_)\n",
    "    mlflow.log_metrics(metrics_gbm)\n",
    "    mlflow.sklearn.log_model(best_gbm, \"model\")\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    print(f\"Logged GBM model to MLflow run {run_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae26ab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution BEFORE SMOTE:\n",
      "is_high_risk\n",
      "0    0.941787\n",
      "1    0.058213\n",
      "Name: proportion, dtype: float64\n",
      "Class distribution AFTER SMOTE:\n",
      "is_high_risk\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, scale_pos_weight=2, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, scale_pos_weight=2, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, scale_pos_weight=2, subsample=0.8; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, scale_pos_weight=1, subsample=1.0; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, scale_pos_weight=1, subsample=1.0; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, scale_pos_weight=1, subsample=1.0; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=100, scale_pos_weight=1, subsample=0.6; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=100, scale_pos_weight=1, subsample=0.6; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, scale_pos_weight=2, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, scale_pos_weight=2, subsample=1.0; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=100, scale_pos_weight=1, subsample=0.6; total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, scale_pos_weight=2, subsample=1.0; total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [15:38:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, scale_pos_weight=2, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, scale_pos_weight=2, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, scale_pos_weight=2, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=6, n_estimators=500, scale_pos_weight=5, subsample=0.8; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=300, scale_pos_weight=2, subsample=0.8; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=300, scale_pos_weight=2, subsample=0.8; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=300, scale_pos_weight=2, subsample=0.8; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=300, scale_pos_weight=1, subsample=0.6; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=300, scale_pos_weight=1, subsample=0.6; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=300, scale_pos_weight=1, subsample=0.6; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=6, n_estimators=500, scale_pos_weight=5, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=6, n_estimators=500, scale_pos_weight=5, subsample=0.8; total time=   5.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time=   9.3s\n",
      "Best XGB params: {'subsample': 0.6, 'scale_pos_weight': 1, 'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "\n",
      "Optimal Threshold found: 0.20\n",
      "Best F1 score at optimal threshold: 0.3855\n",
      "\n",
      "XGBoost Metrics after SMOTE + Threshold Tuning:\n",
      "accuracy: 0.8880\n",
      "precision: 0.2832\n",
      "recall: 0.6038\n",
      "f1: 0.3855\n",
      "roc_auc: 0.9132\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9737    0.9055    0.9384     14415\n",
      "           1     0.2832    0.6038    0.3855       891\n",
      "\n",
      "    accuracy                         0.8880     15306\n",
      "   macro avg     0.6284    0.7547    0.6619     15306\n",
      "weighted avg     0.9335    0.8880    0.9062     15306\n",
      "\n",
      "Logged XGBoost model to MLflow run e6e800a33f6046cbb9aa08b18f2c1bc5\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    ")\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Drop leakage columns if present\n",
    "# ---------------------------------------------------\n",
    "cols_to_drop = [\"FraudResult\"]\n",
    "\n",
    "for col in cols_to_drop:\n",
    "    if col in X_train.columns:\n",
    "        X_train = X_train.drop(columns=[col])\n",
    "    if col in X_val.columns:\n",
    "        X_val = X_val.drop(columns=[col])\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# SMOTE\n",
    "# ---------------------------------------------------\n",
    "print(\"Class distribution BEFORE SMOTE:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution AFTER SMOTE:\")\n",
    "print(y_train_smote.value_counts(normalize=True))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# XGBoost Hyperparameter Tuning\n",
    "# ---------------------------------------------------\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [3, 6, 10],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"scale_pos_weight\": [1, 2, 5],  # handle imbalance\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "search_xgb = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "search_xgb.fit(X_train_smote, y_train_smote)\n",
    "best_xgb = search_xgb.best_estimator_\n",
    "\n",
    "print(\"Best XGB params:\", search_xgb.best_params_)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Ensure columns match in validation set\n",
    "# ---------------------------------------------------\n",
    "missing_cols = set(X_train_smote.columns) - set(X_val.columns)\n",
    "for col in missing_cols:\n",
    "    X_val[col] = 0\n",
    "\n",
    "# Reorder columns to match\n",
    "X_val = X_val[X_train_smote.columns]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Predict probabilities on Validation Set\n",
    "# ---------------------------------------------------\n",
    "y_prob_xgb = best_xgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Threshold Tuning\n",
    "# ---------------------------------------------------\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "best_thresh = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (y_prob_xgb >= t).astype(int)\n",
    "    f1 = f1_score(y_val, preds, zero_division=0)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"\\nOptimal Threshold found: {best_thresh:.2f}\")\n",
    "print(f\"Best F1 score at optimal threshold: {best_f1:.4f}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Final predictions and metrics\n",
    "# ---------------------------------------------------\n",
    "y_pred_xgb = (y_prob_xgb >= best_thresh).astype(int)\n",
    "\n",
    "metrics_xgb = {\n",
    "    \"accuracy\": accuracy_score(y_val, y_pred_xgb),\n",
    "    \"precision\": precision_score(y_val, y_pred_xgb, zero_division=0),\n",
    "    \"recall\": recall_score(y_val, y_pred_xgb, zero_division=0),\n",
    "    \"f1\": f1_score(y_val, y_pred_xgb, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(y_val, y_prob_xgb),\n",
    "}\n",
    "\n",
    "print(\"\\nXGBoost Metrics after SMOTE + Threshold Tuning:\")\n",
    "for k, v in metrics_xgb.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_xgb, digits=4))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# MLflow Logging\n",
    "# ---------------------------------------------------\n",
    "mlflow.set_experiment(\"credit-risk-modeling\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGBoost_SMOTE_ThresholdTuned\") as run:\n",
    "    mlflow.log_params(search_xgb.best_params_)\n",
    "    mlflow.log_metrics(metrics_xgb)\n",
    "    mlflow.xgboost.log_model(best_xgb, \"model\")\n",
    "    mlflow.log_param(\"optimal_threshold\", best_thresh)\n",
    "    print(\"Logged XGBoost model to MLflow run\", run.info.run_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
