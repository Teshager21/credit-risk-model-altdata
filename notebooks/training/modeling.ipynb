{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16135a5",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4483868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# ðŸ“¦ Imports\n",
    "# -----------------------------------------------\n",
    "from features.preprocess import drop_leakage_cols, apply_smote\n",
    "from data.load_data import load_processed_data\n",
    "from models.logistic_regression import train_logistic_regression\n",
    "from models.random_forest import train_random_forest\n",
    "from models.gradient_boosting import train_gradient_boosting\n",
    "from models.xgboost_model import train_xgboost\n",
    "from utils.metrics import evaluate_model, threshold_tuning, print_classification_report\n",
    "from utils.mlflow_utils import setup_mlflow, log_model_mlflow\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6479fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# ðŸ“¦ Load Data\n",
    "# -----------------------------------------------\n",
    "X, y = load_processed_data(\"../../data/processed/processed_data.parquet\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81a1841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics: {'accuracy': 0.5715405723245786, 'precision': 0.11776608660461352, 'recall': 0.9797979797979798, 'f1': 0.21026011560693642, 'roc_auc': 0.7787303800715756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# ðŸ“¦ Logistic Regression\n",
    "# -----------------------------------------------\n",
    "lr_model = train_logistic_regression(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_prob_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "lr_metrics = evaluate_model(y_test, y_pred_lr, y_prob_lr)\n",
    "print(\"Logistic Regression Metrics:\", lr_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a8e9318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=  23.2s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=  23.9s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=100; total time=  24.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=  23.9s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=  24.6s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=  12.6s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=  15.7s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=  15.3s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=  42.5s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=300; total time=  43.5s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=  21.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=  45.7s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=300; total time=  45.5s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=  46.3s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=300; total time=  47.4s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=5, min_samples_split=10, n_estimators=500; total time=  40.7s\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=None, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=5, min_samples_split=10, n_estimators=500; total time=  34.8s\n",
      "[CV] END max_depth=5, min_samples_split=10, n_estimators=500; total time=  35.1s\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=500; total time= 1.5min\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=500; total time= 1.5min\n",
      "[CV] END max_depth=20, min_samples_split=10, n_estimators=500; total time= 1.6min\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=500; total time= 1.6min\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=500; total time= 1.6min\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=500; total time=  54.6s\n",
      "[CV] END max_depth=None, min_samples_split=10, n_estimators=500; total time= 1.6min\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=500; total time=  57.8s\n",
      "[CV] END max_depth=10, min_samples_split=10, n_estimators=500; total time= 1.0min\n",
      "\n",
      "Random Forest Metrics: {'accuracy': 0.8762576767280805, 'precision': 0.26175771971496437, 'recall': 0.6184062850729517, 'f1': 0.3678237650200267, 'roc_auc': 0.9049782520935256}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9742    0.8922    0.9314     14415\n",
      "           1     0.2618    0.6184    0.3678       891\n",
      "\n",
      "    accuracy                         0.8763     15306\n",
      "   macro avg     0.6180    0.7553    0.6496     15306\n",
      "weighted avg     0.9328    0.8763    0.8986     15306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# ðŸ“¦ Random Forest\n",
    "# -----------------------------------------------\n",
    "cols_to_drop = [\"FraudResult\"]\n",
    "X_train_clean = drop_leakage_cols(X_train, cols_to_drop)\n",
    "\n",
    "X_train_smote, y_train_smote = apply_smote(X_train_clean, y_train)\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [5, 10, 20, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "}\n",
    "\n",
    "best_rf, best_params_rf = train_random_forest(X_train_smote, y_train_smote, param_grid_rf)\n",
    "\n",
    "X_test_clean = drop_leakage_cols(X_test, cols_to_drop)\n",
    "y_prob_rf = best_rf.predict_proba(X_test_clean)[:, 1]\n",
    "best_thresh_rf, best_f1_rf = threshold_tuning(y_test, y_prob_rf)\n",
    "y_pred_rf = (y_prob_rf >= best_thresh_rf).astype(int)\n",
    "rf_metrics = evaluate_model(y_test, y_pred_rf, y_prob_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Metrics:\", rf_metrics)\n",
    "print_classification_report(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "511504dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=  34.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=  34.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=  34.3s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=  35.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=  35.5s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=  35.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=  52.6s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=  52.4s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=  53.5s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=  53.9s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=  54.9s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time= 1.0min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time= 1.1min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time= 1.1min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time= 1.1min\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time= 1.1min\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=  43.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time= 1.4min\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time= 1.5min\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time= 1.5min\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time= 1.2min\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time= 1.2min\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time= 1.2min\n",
      "\n",
      "Gradient Boosting Metrics: {'accuracy': 0.9019992159937279, 'precision': 0.2935593220338983, 'recall': 0.48597081930415265, 'f1': 0.36601859678782755, 'roc_auc': 0.9060830293920824}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9669    0.9277    0.9469     14415\n",
      "           1     0.2936    0.4860    0.3660       891\n",
      "\n",
      "    accuracy                         0.9020     15306\n",
      "   macro avg     0.6302    0.7068    0.6565     15306\n",
      "weighted avg     0.9277    0.9020    0.9131     15306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# ðŸ“¦ Gradient Boosting\n",
    "# -----------------------------------------------\n",
    "param_grid_gbm = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"subsample\": [0.8],\n",
    "}\n",
    "\n",
    "best_gbm, best_params_gbm = train_gradient_boosting(X_train_smote, y_train_smote, param_grid_gbm)\n",
    "# GBM predictions\n",
    "y_pred_gbm = best_gbm.predict(X_test_clean)\n",
    "y_prob_gbm = best_gbm.predict_proba(X_test_clean)[:, 1]\n",
    "\n",
    "gbm_metrics = evaluate_model(y_test, y_pred_gbm, y_prob_gbm)\n",
    "\n",
    "print(\"\\nGradient Boosting Metrics:\", gbm_metrics)\n",
    "print_classification_report(y_test, y_pred_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1349b2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, scale_pos_weight=2, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, scale_pos_weight=2, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=6, n_estimators=100, scale_pos_weight=2, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, scale_pos_weight=1, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, scale_pos_weight=1, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=6, n_estimators=100, scale_pos_weight=1, subsample=1.0; total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=100, scale_pos_weight=1, subsample=0.6; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=100, scale_pos_weight=1, subsample=0.6; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, scale_pos_weight=2, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, scale_pos_weight=2, subsample=1.0; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=100, scale_pos_weight=1, subsample=0.6; total time=   1.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=10, n_estimators=100, scale_pos_weight=2, subsample=1.0; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, scale_pos_weight=2, subsample=1.0; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, scale_pos_weight=2, subsample=1.0; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=3, n_estimators=500, scale_pos_weight=2, subsample=1.0; total time=   4.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time=   4.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=300, scale_pos_weight=2, subsample=0.8; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=300, scale_pos_weight=2, subsample=0.8; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=300, scale_pos_weight=1, subsample=0.6; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=6, n_estimators=500, scale_pos_weight=5, subsample=0.8; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=6, n_estimators=500, scale_pos_weight=5, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=10, n_estimators=300, scale_pos_weight=2, subsample=0.8; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=6, n_estimators=500, scale_pos_weight=5, subsample=0.8; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=300, scale_pos_weight=1, subsample=0.6; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=300, scale_pos_weight=1, subsample=0.6; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=10, n_estimators=500, scale_pos_weight=1, subsample=0.6; total time=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:56:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Metrics: {'accuracy': 0.887952436952829, 'precision': 0.2831578947368421, 'recall': 0.6038159371492705, 'f1': 0.38552490146900753, 'roc_auc': 0.9132033325119231}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9737    0.9055    0.9384     14415\n",
      "           1     0.2832    0.6038    0.3855       891\n",
      "\n",
      "    accuracy                         0.8880     15306\n",
      "   macro avg     0.6284    0.7547    0.6619     15306\n",
      "weighted avg     0.9335    0.8880    0.9062     15306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# ðŸ“¦ XGBoost\n",
    "# -----------------------------------------------\n",
    "param_grid_xgb = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"max_depth\": [3, 6, 10],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"scale_pos_weight\": [1, 2, 5],\n",
    "}\n",
    "\n",
    "best_xgb, best_params_xgb = train_xgboost(X_train_smote, y_train_smote, param_grid_xgb)\n",
    "\n",
    "# XGBoost predictions\n",
    "y_prob_xgb = best_xgb.predict_proba(X_test_clean)[:, 1]\n",
    "best_thresh_xgb, best_f1_xgb = threshold_tuning(y_test, y_prob_xgb)\n",
    "y_pred_xgb = (y_prob_xgb >= best_thresh_xgb).astype(int)\n",
    "xgb_metrics = evaluate_model(y_test, y_pred_xgb, y_prob_xgb)\n",
    "\n",
    "print(\"\\nXGBoost Metrics:\", xgb_metrics)\n",
    "print_classification_report(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e1ac6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'CreditRiskModel' already exists. Creating a new version of this model...\n",
      "2025/06/30 12:56:50 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: CreditRiskModel, version 3\n",
      "Created version '3' of model 'CreditRiskModel'.\n",
      "/home/teshager/Documents/10Academy/repositories/projects/credit-risk-model-altdata/venv/lib/python3.10/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:56:50] WARNING: /workspace/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered model 'CreditRiskModel' as version 3\n",
      "Moved model version 3 to stage 'Production'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'CreditRiskModel' already exists. Creating a new version of this model...\n",
      "2025/06/30 12:56:51 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: CreditRiskModel, version 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered model 'CreditRiskModel' as version 4\n",
      "Moved model version 4 to stage 'Production'\n",
      "Random Forest run ID: eec6ca038f764c54b2003080c8763888\n",
      "XGBoost run ID: 348c63120b4241458b5f584dd0d62669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '4' of model 'CreditRiskModel'.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------\n",
    "# ðŸ“¦ MLflow Logging\n",
    "# -----------------------------------------------\n",
    "setup_mlflow()\n",
    "\n",
    "rf_run_id = log_model_mlflow(\n",
    "    best_rf,\n",
    "    model_name=\"CreditRiskModel\",\n",
    "    params=best_params_rf,\n",
    "    metrics=rf_metrics,\n",
    "    threshold=best_thresh_rf,\n",
    "    run_name=\"RandomForest_SMOTE_ThresholdTuned\",\n",
    "    flavor=\"sklearn\",\n",
    "    register=True,             # âœ… NEW\n",
    "    stage=\"Production\",        # âœ… NEW\n",
    ")\n",
    "\n",
    "xgb_run_id = log_model_mlflow(\n",
    "    best_xgb,\n",
    "    model_name=\"CreditRiskModel\",\n",
    "    params=best_params_xgb,\n",
    "    metrics=xgb_metrics,\n",
    "    threshold=best_thresh_xgb,\n",
    "    run_name=\"XGBoost_SMOTE_ThresholdTuned\",\n",
    "    flavor=\"xgboost\",\n",
    "    register=True,             # âœ… NEW\n",
    "    stage=\"Production\",        # âœ… NEW\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Random Forest run ID: {rf_run_id}\")\n",
    "print(f\"XGBoost run ID: {xgb_run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39b1b288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datetime__TransactionStartTime_hour', 'datetime__TransactionStartTime_day', 'datetime__TransactionStartTime_month', 'datetime__TransactionStartTime_weekday', 'datetime__TransactionStartTime_year', 'numeric__Amount', 'numeric__Value', 'numeric__Amount_log', 'numeric__Amount_capped', 'numeric__total_transaction_amount', 'numeric__avg_transaction_amount', 'numeric__transaction_count', 'numeric__std_transaction_amount', 'woe__ProductCategory_woe', 'woe__ChannelId_woe', 'woe__ProviderId_woe', 'woe__ProductId_woe', 'onehot__PricingStrategy_0', 'onehot__PricingStrategy_1', 'onehot__PricingStrategy_2', 'onehot__PricingStrategy_4', 'onehot__is_large_transaction_0', 'onehot__is_large_transaction_1', 'is_high_risk', 'FraudResult']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"../../data/processed/processed_data.parquet\")\n",
    "print(df.columns.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
